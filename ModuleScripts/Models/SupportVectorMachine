local MachineLearningBaseModel = require(script.Parent.MachineLearningBaseModel)

SupportVectorMachineModel = {}

SupportVectorMachineModel.__index = SupportVectorMachineModel

setmetatable(SupportVectorMachineModel, MachineLearningBaseModel)

local AqwamMatrixLibrary = require(script.Parent.Parent.AqwamRobloxMatrixLibraryLinker.Value)

local defaultMaxNumberOfIterations = 500

local defaultLearningRate = 0.3

local defaultCvalue = 0.3

local defaultDistanceFunction = "euclidean"

local defaultTargetCost = 0

local distanceFunctionList = {

	["manhattan"] = function (y, h) return math.abs(y - h) end,

	["euclidean"] = function (y, h) return (y - h)^2 end,

}

local function calculateManhattanDistance(vector1, vector2)

	local distance = 0

	for row = 1, #vector1, 1 do

		distance += distanceFunctionList["manhattan"](vector1[row][1], vector2[row][1])

	end

	return distance

end

local function calculateEuclideanDistance(vector1, vector2)

	local squaredDistance = 0

	for row = 1, #vector1, 1 do

		squaredDistance += distanceFunctionList["euclidean"](vector1[row][1], vector2[row][1])

	end

	local distance = math.sqrt(squaredDistance)

	return distance

end

local function calculateDistance(vector1, vector2, distanceFunction)

	local distance

	if (distanceFunction == "euclidean") then

		distance = calculateEuclideanDistance(vector1, vector2)

	elseif (distanceFunction == "manhattan") then

		distance = calculateManhattanDistance(vector1, vector2)

	end

	return distance 

end

local function calculateCost(modelParameters, featureMatrix, labelVector, distanceFunction, cValue)
	
	local hypothesisVector = AqwamMatrixLibrary:dotProduct(featureMatrix, modelParameters)
	
	local distanceVector = calculateDistance(hypothesisVector, labelVector, distanceFunction)
	
	local squaredDistanceVector = AqwamMatrixLibrary:multiply(distanceVector, distanceVector)
	
	local sum = AqwamMatrixLibrary:sum(squaredDistanceVector)
	
	local cost = (1/2 * sum)

	return cost

end

local function gradientDescent(modelParameters, featureMatrix, labelVector, distanceFunction, cValue)

	local numberOfData = #featureMatrix

	local hypothesisVector = AqwamMatrixLibrary:dotProduct(featureMatrix, modelParameters)

	local calculatedError = AqwamMatrixLibrary:subtract(hypothesisVector, labelVector)
	
	local calculatedErrorWithFeatureMatrix = AqwamMatrixLibrary:multiply(calculatedError, featureMatrix)

	local calculatedSumError =  AqwamMatrixLibrary:verticalSum(calculatedError)

	local costFunctionDerivatives = AqwamMatrixLibrary:multiply((1/numberOfData), calculatedSumError)

	return costFunctionDerivatives

end

function SupportVectorMachineModel.new(maxNumberOfIterations, learningRate, cValue, distanceFunction, targetCost)
	
	local NewSupportVectorMachine = MachineLearningBaseModel.new()
	
	setmetatable(NewSupportVectorMachine, SupportVectorMachineModel)
	
	NewSupportVectorMachine.maxNumberOfIterations = maxNumberOfIterations or defaultMaxNumberOfIterations

	NewSupportVectorMachine.learningRate = learningRate or defaultLearningRate
	
	NewSupportVectorMachine.cValue = cValue or defaultCvalue

	NewSupportVectorMachine.distanceFunction = distanceFunction or defaultDistanceFunction

	NewSupportVectorMachine.targetCost = targetCost or defaultTargetCost

	NewSupportVectorMachine.validationFeatureMatrix = nil

	NewSupportVectorMachine.validationLabelVector = nil
	
	NewSupportVectorMachine.Optimizer = nil
	
	return NewSupportVectorMachine

end

function SupportVectorMachineModel:setParameters(maxNumberOfIterations, learningRate, cValue, distanceFunction, targetCost)

	self.maxNumberOfIterations = maxNumberOfIterations or self.maxNumberOfIterations

	self.learningRate = learningRate or self.learningRate
	
	self.cValue = cValue or self.cValue

	self.distanceFunction = distanceFunction or self.distanceFunction

	self.targetCost = targetCost or self.targetCost

end

function SupportVectorMachineModel:train(featureMatrix, labelVector)
	
	local cost

	local costArray = {}

	local numberOfIterations = 0
	
	local costFunctionDerivatives

	if (#featureMatrix ~= #labelVector) then error("The feature matrix and the label vector does not contain the same number of rows!") end

	if (self.ModelParameters) then

		if (#featureMatrix[1] ~= #self.ModelParameters[1]) then error("The number of features are not the same as the model parameters!") end

	else

		self.ModelParameters = AqwamMatrixLibrary:createRandomMatrix(#featureMatrix[1], 1)

	end	

	repeat

		numberOfIterations += 1
		
		costFunctionDerivatives = gradientDescent(self.ModelParameters, featureMatrix, labelVector, self.distanceFunction, self.learningRate, self.cValue)

		if (self.Optimizer) then

			costFunctionDerivatives = self.Optimizer:calculate(self.ModelParameters, costFunctionDerivatives, self.learningRate)

		else

			costFunctionDerivatives = AqwamMatrixLibrary:multiply(self.learningRate, costFunctionDerivatives)

		end

		self.ModelParameters = AqwamMatrixLibrary:add(self.ModelParameters, costFunctionDerivatives)

		cost = calculateCost(self.ModelParameters, featureMatrix, labelVector, self.distanceFunction, self.learningRate, self.cValue)
		
		table.insert(costArray, cost)
		
		MachineLearningBaseModel:printCostAndNumberOfIterations(cost, numberOfIterations, self.IsOutputPrinted)

	until (numberOfIterations == self.maxNumberOfIterations) or (math.abs(cost) <= self.targetCost)

	if (cost == math.huge) then warn("The model diverged! Please repeat the experiment again or change the argument values.") end

	return costArray

end

function SupportVectorMachineModel:predict(featureMatrix)
	
	local hypothesis = AqwamMatrixLibrary:dotProduct(featureMatrix, self.ModelParameters)
	
	if (hypothesis > 0) then
		
		return 1
		
	elseif (hypothesis < 0) then
		
		return -1
		
	end 

end

return SupportVectorMachineModel

