local GradientDescentModes = {}

local function runMachineLearningModel(MachineLearningModel, suppressOutput, argumentsArray)
	
	local numberOfArguments = #argumentsArray
	
	local featureMatrix = argumentsArray[1]
	
	if (numberOfArguments == 2) then
		
		local labelVector = argumentsArray[2]
		
		MachineLearningModel:train(featureMatrix, labelVector, suppressOutput)
		
	else
		
		MachineLearningModel:train(featureMatrix, suppressOutput)
		
	end
	
end

local function breakFeatureMatrixToBatches(featureMatrix, labelVector, batchSize)
	
	local numberOfWholeBatches = math.floor( (#featureMatrix) / batchSize )
	
	local featureMatrixPositionArray = {1}
	
	local featureMatrixBatchesTable = {}
	
	local currentBatchNumber = 0
	
	local newFeatureMatrix
	
	for i = 1, numberOfWholeBatches, 1 do table.insert(featureMatrixPositionArray, (i * batchSize)) end
	
	table.insert(featureMatrixPositionArray, #featureMatrix)
	
	repeat
		
		newFeatureMatrix = {}
		
		for j = (currentBatchNumber * batchSize) + 1, batchSize, 1 do table.insert(newFeatureMatrix, featureMatrix[j]) end
		
		table.insert(featureMatrixBatchesTable, newFeatureMatrix)
		
		currentBatchNumber += 1
		
	until (currentBatchNumber == numberOfWholeBatches)
	
	newFeatureMatrix = {}
	
	local totalBatches = (numberOfWholeBatches * batchSize)
	
	for j = (totalBatches + 1), (#featureMatrix - totalBatches), 1 do 

		table.insert(newFeatureMatrix, featureMatrix[j])

	end

	table.insert(featureMatrixBatchesTable, newFeatureMatrix)
	
	return featureMatrixBatchesTable
	
end

function GradientDescentModes:startBatchGradientDescent(MachineLearningModel, suppressOutput, ...)
	
	local argumentsArray = {...}
	
	runMachineLearningModel(MachineLearningModel, suppressOutput, argumentsArray)
	
end

function GradientDescentModes:startMiniBatchGradientDescent(MachineLearningModel, suppressOutput, batchSize, ...)
	
	local argumentsArray = {...}
	
	local featureMatrix = argumentsArray[1]
	
	local featureMatrixBatchesTable = breakFeatureMatrixToBatches(featureMatrix, batchSize)
	
	local numberOfBatches = math.floor( ( #featureMatrix) / batchSize ) + 1
	
	local batchFeatureMatrix
	
	local newArgumentsArray
	
	local currentBatchNumber = 0
	
	repeat
		
		currentBatchNumber += 1
		
		batchFeatureMatrix = featureMatrixBatchesTable[currentBatchNumber]
		
		newArgumentsArray = {batchFeatureMatrix,  argumentsArray[2]}
		
		runMachineLearningModel(MachineLearningModel, suppressOutput, newArgumentsArray)
		
	until (currentBatchNumber == numberOfBatches)

end

function GradientDescentModes:startStochasticGradientDescent(MachineLearningModel, suppressOutput, ...)
	
	local argumentsArray = {...}

	runMachineLearningModel(MachineLearningModel, suppressOutput, argumentsArray)

end

return GradientDescentModes

