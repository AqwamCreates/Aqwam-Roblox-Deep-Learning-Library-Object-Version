local GradientDescentModes = {}

local function runMachineLearningModel(MachineLearningModel, suppressOutput, argumentsArray)
	
	local numberOfArguments = #argumentsArray
	
	local featureMatrix = argumentsArray[1]
	
	if (numberOfArguments == 2) then
		
		local labelVector = argumentsArray[2]
		
		MachineLearningModel:train(featureMatrix, labelVector, suppressOutput)
		
	else
		
		MachineLearningModel:train(featureMatrix, suppressOutput)
		
	end
	
end

local function breakFeatureMatrixToBatches(batchSize, featureMatrix, labelVector)
	
	local numberOfWholeBatches = math.floor( (#featureMatrix) / batchSize )
	
	local dataPositionArray = {1}
	
	local featureMatrixBatchesTable = {}
	
	local labelVectorBatchesTable = {}
	
	local currentBatchNumber = 0
	
	local newFeatureMatrix
	
	local newLabelVector 
	
	for i = 1, numberOfWholeBatches, 1 do table.insert(dataPositionArray, (i * batchSize)) end
	
	table.insert(dataPositionArray, #featureMatrix)
	
	repeat
		
		newFeatureMatrix = {}
		
		newLabelVector = {}
		
		for j = (currentBatchNumber * batchSize) + 1, batchSize, 1 do 
			
			table.insert(newFeatureMatrix, featureMatrix[j]) 
			
			if (labelVector) then table.insert(newLabelVector, labelVector[j]) end
			
		end
		
		table.insert(featureMatrixBatchesTable, newFeatureMatrix)
		table.insert(labelVectorBatchesTable, newLabelVector)
		
		currentBatchNumber += 1
		
	until (currentBatchNumber == numberOfWholeBatches)
	
	newFeatureMatrix = {}
	
	local totalBatches = (numberOfWholeBatches * batchSize)
	
	for j = (totalBatches + 1), (#featureMatrix - totalBatches), 1 do 

		table.insert(newFeatureMatrix, featureMatrix[j])
		
		if (labelVector) then table.insert(newLabelVector, labelVector[j]) end

	end

	table.insert(featureMatrixBatchesTable, newFeatureMatrix)
	table.insert(labelVectorBatchesTable, newLabelVector)
	
	return featureMatrixBatchesTable, labelVectorBatchesTable
	
end

function GradientDescentModes:startBatchGradientDescent(MachineLearningModel, suppressOutput, ...)
	
	local argumentsArray = {...}
	
	runMachineLearningModel(MachineLearningModel, suppressOutput, argumentsArray)
	
end

function GradientDescentModes:startMiniBatchGradientDescent(MachineLearningModel, suppressOutput, batchSize, ...)
	
	local argumentsArray = {...}
	
	local featureMatrix = argumentsArray[1]
	
	local labelVector = argumentsArray[2]
	
	local featureMatrixBatchesTable, labelVectorBatchesTable = breakFeatureMatrixToBatches(batchSize, featureMatrix, labelVector)
	
	local numberOfBatches = math.floor( ( #featureMatrix) / batchSize ) + 1
	
	local batchFeatureMatrix
	
	local batchLabelVector
	
	local newArgumentsArray
	
	local currentBatchNumber = 0
	
	repeat
		
		currentBatchNumber += 1
		
		batchFeatureMatrix = featureMatrixBatchesTable[currentBatchNumber]
		
		batchLabelVector = labelVectorBatchesTable[currentBatchNumber]
		
		newArgumentsArray = {batchFeatureMatrix, batchLabelVector}
		
		runMachineLearningModel(MachineLearningModel, suppressOutput, newArgumentsArray)
		
	until (currentBatchNumber == numberOfBatches)

end

function GradientDescentModes:startStochasticGradientDescent(MachineLearningModel, suppressOutput, ...)
	
	local argumentsArray = {...}

	runMachineLearningModel(MachineLearningModel, suppressOutput, argumentsArray)

end

return GradientDescentModes
