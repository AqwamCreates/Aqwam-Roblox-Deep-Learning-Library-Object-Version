local GradientDescentModes = {}

local function breakFeatureMatrixToBatches(batchSize, featureMatrix, labelVector)
	
	local numberOfWholeBatches = math.floor( (#featureMatrix) / batchSize )
	
	local dataPositionArray = {1}
	
	local featureMatrixBatchesTable = {}
	
	local labelVectorBatchesTable = {}
	
	local currentBatchNumber = 0
	
	local newFeatureMatrix
	
	local newLabelVector 
	
	for i = 1, numberOfWholeBatches, 1 do table.insert(dataPositionArray, (i * batchSize)) end
	
	table.insert(dataPositionArray, #featureMatrix)
	
	repeat
		
		newFeatureMatrix = {}
		
		newLabelVector = {}
		
		for j = (currentBatchNumber * batchSize) + 1, batchSize, 1 do 
			
			table.insert(newFeatureMatrix, featureMatrix[j]) 
			
			if (labelVector) then table.insert(newLabelVector, labelVector[j]) end
			
		end
		
		table.insert(featureMatrixBatchesTable, newFeatureMatrix)
		table.insert(labelVectorBatchesTable, newLabelVector)
		
		currentBatchNumber += 1
		
	until (currentBatchNumber == numberOfWholeBatches)
	
	newFeatureMatrix = {}
	
	local totalBatches = (numberOfWholeBatches * batchSize)
	
	for j = (totalBatches + 1), (#featureMatrix - totalBatches), 1 do 

		table.insert(newFeatureMatrix, featureMatrix[j])
		
		if (labelVector) then table.insert(newLabelVector, labelVector[j]) end

	end

	table.insert(featureMatrixBatchesTable, newFeatureMatrix)
	table.insert(labelVectorBatchesTable, newLabelVector)
	
	return featureMatrixBatchesTable, labelVectorBatchesTable
	
end

local function startBatchGradientDescent(MachineLearningModel, featureMatrix, labelVector)
	
	MachineLearningModel:train(featureMatrix, labelVector)
	
end

local function startMiniBatchGradientDescent(MachineLearningModel, featureMatrix, labelVector, batchSize)
	
	local featureMatrixBatchesTable, labelVectorBatchesTable = breakFeatureMatrixToBatches(batchSize, featureMatrix, labelVector)
	
	local numberOfBatches = math.floor( (#featureMatrix) / batchSize ) + 1
	
	local batchFeatureMatrix
	
	local batchLabelVector
	
	local dataArray
	
	for currentBatchNumber = 1, numberOfBatches, 1 do

		batchFeatureMatrix = featureMatrixBatchesTable[currentBatchNumber]

		batchLabelVector = labelVectorBatchesTable[currentBatchNumber]

		dataArray = {batchFeatureMatrix, batchLabelVector}

		MachineLearningModel:train(featureMatrix, labelVector)
		
	end

end

local function startStochasticGradientDescent(MachineLearningModel, featureMatrix, labelVector)
	
	local featureVector
	
	local label
	
	for row = 1, #featureMatrix, 1 do
		
		local featureVector = {featureMatrix[row]}
		
		local label = {labelVector[row]}
		
		MachineLearningModel:train(featureVector, label)
		
	end

end

function GradientDescentModes:startGradientDescent(MachineLearningModel, gradientDescentAlgorithmType, featureMatrix, labelVector, batchSize)
	
	if (gradientDescentAlgorithmType == "Batch") then
		
		startBatchGradientDescent(MachineLearningModel, featureMatrix, labelVector)
		
	elseif (GradientDescentModes == "Minibatch") then
		
		batchSize = batchSize or 2
		
		startMiniBatchGradientDescent(MachineLearningModel, featureMatrix, labelVector, batchSize)
		
	elseif (gradientDescentAlgorithmType == "Stochastic") then
		
		startStochasticGradientDescent(MachineLearningModel, featureMatrix, labelVector)
		
	else
		
		error("The Selected Gradient Descent Algorithm Type Cannot Be Found!")
		
	end
	
end

return GradientDescentModes

