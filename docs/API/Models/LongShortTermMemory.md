# [API Reference](../../API.md) - [Models](../Models.md) - RecurrentNeuralNetwork

LongShortTermMemory is a supervised machine learning model that predicts a sequence of positive numbers of discrete values (a.k.a. tokens).

## Stored Model Parameters

Contains a table of matrices.  

* ModelParameters[1]: Input weight matrix.

* ModelParameters[2]: Hidden weight matrix.

* ModelParameters[3]: Output weight matrix.

* ModelParameters[4]: Hidden bias matrix.

* ModelParameters[5]: Output bias matrix.

## Constructors

### new()

Create new model object. If any of the arguments are nil, default argument values for that argument will be used.

```
LongShortTermMemory.new(maxNumberOfIterations: integer, learningRate: number, targetCost: number): ModelObject
```

#### Parameters:

* maxNumberOfIterations: How many times should the model needed to be trained.

* learningRate: The speed at which the model learns. Recommended that the value is set between (0 to 1).

* targetCost: The cost at which the model stops training.

#### Returns:

* ModelObject: The generated model object.

## Functions

### setParameters()

Set model's parameters. When any of the arguments are nil, previous argument values for that argument will be used.

```
LongShortTermMemory:setParameters(maxNumberOfIterations: integer, learningRate: number, targetCost: number)
```

#### Parameters:

* tokenSize: The number of unique tokens that will be inputed or generated by the model.

* maxNumberOfIterations: How many times should the model needed to be trained.

* learningRate: The speed at which the model learns. Recommended that the value is set between (0 to 1).

* targetCost: The cost at which the model stops training.

### createLayers()

Create layers of the recurrent neural network.

```
LongShortTermMemory:createLayers(inputSize: integer, hiddenSize: integer, outputSize: integer)
```

* inputSize: The number of unique tokens to be inputted to the model.

* hiddenSize: The number of neurons inside the model.

* otuputSize: The number of unique tokens to be generated by the model.

### train()

Train the model. 

```
LongShortTermMemory:train(tokenInputSequenceArray: integer[], tokenOutputSequenceArray: integer[]): number[]
```
#### Parameters:

* tokenInputSequenceArray: An array containing a sequence of tokens.

* tokenOutputSequenceArray: An array containing a sequence of tokens. Leave this empty if you want to use tokenInputSequenceArray only.

#### Returns:

* costArray: An array containing cost values.

### predict()

* Predict a sequence of output tokens for a given sequence of input tokens.

```
LongShortTermMemory:predict(tokenInputSequenceArray: integer[]): integer[]
```

#### Parameters:

* tokenInputSequenceArray: An array containing a sequence of tokens.

#### Returns:

* tokenOutputSequenceArray: An array containing a sequence of tokens.

## Notes:

* Ensure that the length of input tokens is equal to ouput tokens if output tokens are used.

* For an uneven lengths of tokens, I recommend that you "pad" the token arrays with nil values. For example, if we have input tokens {1, 3, 4} and output tokens {6, 2, 3, 4}, then use {1, 3, 4, nil, nil, nil, nil} and {nil, nil, nil, 6, 2, 3, 4}.

## Inherited From

* [BaseModel](BaseModel.md)
