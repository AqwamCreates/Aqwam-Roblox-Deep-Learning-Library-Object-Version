# [API Reference](../../API.md) - [Models](../Models.md) - RecurrentNeuralNetwork (RNN)

RecurrentNeuralNetwork is a supervised machine learning model that predicts a sequence of positive numbers of discrete values (a.k.a. tokens).

## Stored Model Parameters

Contains a table of matrices.  

* ModelParameters[1]: Input weight matrix.

* ModelParameters[2]: Hidden weight matrix.

* ModelParameters[3]: Output weight matrix.

* ModelParameters[4]: Hidden bias matrix.

* ModelParameters[5]: Output bias matrix.

## Constructors

### new()

Create new model object. If any of the arguments are nil, default argument values for that argument will be used.

```
RecurrentNeuralNetwork.new(maxNumberOfIterations: integer, learningRate: number, activationFunction: string): ModelObject
```

#### Parameters:

* maxNumberOfIterations: How many times should the model needed to be trained.

* learningRate: The speed at which the model learns. Recommended that the value is set between (0 to 1).

* activationFunction: The activation function to be used in hidden layer. Available functions are "Sigmoid", "Tanh", "ReLU", "LeakyReLU" and "ELU".

* targetCost: The cost at which the model stops training.

#### Returns:

* ModelObject: The generated model object.

## Functions

### setParameters()

Set model's parameters. When any of the arguments are nil, previous argument values for that argument will be used.

```
RecurrentNeuralNetwork:setParameters(maxNumberOfIterations: integer, learningRate: number, activationFunction)
```

#### Parameters:

* tokenSize: The number of unique tokens that will be inputed or generated by the model.

* maxNumberOfIterations: How many times should the model needed to be trained.

* learningRate: The speed at which the model learns. Recommended that the value is set between (0 to 1).

* activationFunction: The activation function to be used in hidden layer. Available functions are "Sigmoid", "Tanh", "ReLU", "LeakyReLU" and "ELU".

* targetCost: The cost at which the model stops training.

### createLayers()

Create layers of the recurrent neural network.

```
RecurrentNeuralNetwork:createLayers(inputSize: integer, hiddenSize: integer, outputSize: integer)
```

* inputSize: The number of unique tokens to be inputted to the model.

* hiddenSize: The number of neurons inside the model.

* outputSize: The number of unique tokens to be generated by the model.

### setOptimizers()

Add optimizers to different matrices.

```
RecurrentNeuralNetwork:setOptimizers(InputLayerOptimizer: OptimizerObject, HiddenLayerOptimizer: OptimizerObject, OutputLayerOptimizer: OptimizerObject, BiasHiddenLayerOptimizer: OptimizerObject, BiasOutputLayerOptimizer: OptimizerObject)
```

#### Parameters:

* InputLayerOptimizer: Optimizer object for input layer calculations.

* HiddenLayerOptimizer: Optimizer object for hidden layer calculations.

* OutputLayerOptimizer: Optimizer object for output layer calculations.

* BiasHiddenLayerOptimizer: Optimizer object for hidden bias layer calculations.

* BiasOutputLayerOptimizer: Optimizer object for output bias layer calculations.

### setRegularizations()

Add regularizations to different matrices.

```
RecurrentNeuralNetwork:setRegularizations(InputLayerRegularization: RegularizationObject, HiddenLayerRegularization: RegularizationObject, OutputLayerRegularization: RegularizationObject, BiasHiddenLayerRegularization: RegularizationObject, BiasOutputLayerRegularization: RegularizationObject)
```

#### Parameters:

* InputLayerRegularization: Regularization object for input layer calculations.

* HiddenLayerRegularization: Regularization object for hidden layer calculations.

* OutputLayerRegularization: Regularization object for output layer calculations.

* BiasHiddenLayerRegularization: Regularization object for hidden bias layer calculations.

* BiasOutputLayerRegularization: Regularization object for output bias layer calculations.

### train()

Train the model. 

```
RecurrentNeuralNetwork:train(LongShortTermMemory:train(tableOfTokenInputSequenceArray: tokenInputSequenceArray[], tableOfTokenOutputSequenceArray: tokenOutputSequenceArray[]): number[]
```
#### Parameters:

* tableOfTokenInputSequenceArray: An array containing sequences of tokens.

* tableOfTokenOutputSequenceArray: An array containing sequences of tokens. Leave this empty if you want to use tokenInputSequenceArray only.

#### Returns:

* costArray: An array containing cost values.

### predict()

Predict a sequence of output tokens for a given sequence of input tokens.

```
RecurrentNeuralNetwork:predict(tableOfTokenInputSequenceArray: tokenInputSequenceArray[], returnreturnOriginalOutput: boolean): tokenOutputSequenceArray[]
```

#### Parameters:

* tableOfTokenInputSequenceArray: An array containing sequences of tokens.

* returnOriginalOutput: Set whether or not to return predicted matrices instead of value with highest probability.

#### Returns:

* tableOfTokenOutputSequenceArray: An array containing sequences of tokens.

## Notes:

* Ensure that the length of input tokens is equal to ouput tokens if output tokens are used.

* For an uneven lengths of tokens, I recommend that you "pad" the token arrays with 0. For example, if we have input tokens {1, 3, 4} and output tokens {6, 2, 3, 4}, then use {1, 3, 4, 0, 0, 0, 0} and {0, 0, 0, 6, 2, 3, 4}.

## Inherited From

* [BaseModel](BaseModel.md)
