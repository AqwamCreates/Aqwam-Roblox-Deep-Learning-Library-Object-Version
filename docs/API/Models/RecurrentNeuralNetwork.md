# [API Reference](../../API.md) - [Models](../Models.md) - RecurrentNeuralNetwork

RecurrentNeuralNetwork is a supervised machine learning model that predicts a sequence of positive numbers of discrete values (a.k.a. tokens).

## Stored Model Parameters

Contains a table of matrices.  

* ModelParameters[1]: Input weight matrix.

* ModelParameters[2]: Hidden weight matrix.

* ModelParameters[3]: Output weight matrix.

* ModelParameters[4]: Hidden bias matrix.

* ModelParameters[5]: Output bias matrix.

## Constructors

### new()

Create new model object. If any of the arguments are nil, default argument values for that argument will be used.

```
RecurrentNeuralNetwork.new(maxNumberOfIterations: integer, learningRate: number, activationFunction: string, targetCost: number): ModelObject
```

#### Parameters:

* maxNumberOfIterations: How many times should the model needed to be trained.

* learningRate: The speed at which the model learns. Recommended that the value is set between (0 to 1).

* activationFunction: The activation function to be used in hidden layer. Available functions are "sigmoid", "tanh", "ReLU", "LeakyReLU" and "ELU".

* targetCost: The cost at which the model stops training.

#### Returns:

* ModelObject: The generated model object.

## Functions

### setParameters()

Set model's parameters. When any of the arguments are nil, previous argument values for that argument will be used.

```
RecurrentNeuralNetwork:setParameters(maxNumberOfIterations: integer, learningRate: number, activationFunction: string, targetCost: number)
```

#### Parameters:

* tokenSize: The number of unique tokens that will be inputed or generated by the model.

* maxNumberOfIterations: How many times should the model needed to be trained.

* learningRate: The speed at which the model learns. Recommended that the value is set between (0 to 1).

* activationFunction: The activation function to be used in hidden layer. Available functions are "sigmoid", "tanh", "ReLU", "LeakyReLU" and "ELU".

* targetCost: The cost at which the model stops training.

### createLayers()

Create layers of the recurrent neural network.

```
RecurrentNeuralNetwork:createLayers(inputSize: integer, hiddenSize: integer, outputSize: integer)
```

* inputSize: The number of unique tokens to be inputted to the model.

* hiddenSize: The number of neurons inside the model.

* outputSize: The number of unique tokens to be generated by the model.

### setOptimizers()

Add optimizers to different matrices.

```
RecurrentNeuralNetwork:setOptimizers(InputLayerOptimizer: OptimizerObject, HiddenLayerOptimizer: OptimizerObject, OutputLayerOptimizer: OptimizerObject, BiasHiddenLayerOptimizer: OptimizerObject, BiasOutputLayerOptimizer: OptimizerObject)
```

#### Parameters:

* InputLayerOptimizer: Optimizer for input layer calculations.

* HiddenLayerOptimizer: Optimizer for hidden layer calculations.

* OutputLayerOptimizer: Optimizer for output layer calculations.

* BiasHiddenLayerOptimizer: Optimizer for hidden bias layer calculations.

* BiasOutputLayerOptimizer: Optimizer for output bias layer calculations.

### train()

Train the model. 

```
RecurrentNeuralNetwork:train(LongShortTermMemory:train(tableOfTokenInputSequenceArray: tableOfTokenInputSequenceArray[], tableOfTokenOutputSequenceArray: tokenOutputSequenceArray[]): number[]
```
#### Parameters:

* tableOfTokenInputSequenceArray: An array containing sequences of tokens.

* tableOfTokenOutputSequenceArray: An array containing sequences of tokens. Leave this empty if you want to use tokenInputSequenceArray only.

#### Returns:

* costArray: An array containing cost values.

### predict()

* Predict a sequence of output tokens for a given sequence of input tokens.

```
RecurrentNeuralNetwork:predict(tokenInputSequenceArray: integer[]): integer[]
```

#### Parameters:

* tokenInputSequenceArray: An array containing a sequence of tokens.

#### Returns:

* tokenOutputSequenceArray: An array containing a sequence of tokens.

## Notes:

* Ensure that the length of input tokens is equal to ouput tokens if output tokens are used.

* For an uneven lengths of tokens, I recommend that you "pad" the token arrays with nil values. For example, if we have input tokens {1, 3, 4} and output tokens {6, 2, 3, 4}, then use {1, 3, 4, nil, nil, nil, nil} and {nil, nil, nil, 6, 2, 3, 4}.

## Inherited From

* [BaseModel](BaseModel.md)
